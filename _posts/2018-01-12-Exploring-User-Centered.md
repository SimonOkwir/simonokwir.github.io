---
layout: post
title: 'Exploring User-Centered Approaches to Understand Hate Speech Online'
date: 2017-07-10
permalink: /posts/2018/01/exploring-user-hate-speech/
tags:
  - machine learning
  - hate speech
  - online social networks
---


Yuri A. Santos ([@santosyurial](https://twitter.com/santosyurial)), 
Manoel Horta Ribeiro ([@manoelribeiro]((https://twitter.com/santosyurial))).

## What is the matter with Hate Speech and Online Social Networks?

The advent of Online Social Networks has deeply transformed the way people communicate with each other in the contemporary world. Some of these platforms are very popular and aggregate millions of users that, on a daily basis, generate and publish a massive (and growing) amount of data, and even though much of the content produced every day consists of funny and interesting cat videos, some of it is not so cute. This would be the case of *Hate Speech*.

But why is it important to address this issue?

Firstly, it is important to consider that spreading Hate Speech is prohibited by law in many countries in which Online Social Networks operate. One interesting example would be Germany, that recently adopted rigid norms aiming to control the spread of Hate Speech, including the possibility of applying expressive fines to Social Media Companies.

Secondly, it’s known that Social Media usually profit from publicity and marketing and, most certainly, companies do not want their ads to be associated with Hate Speech, which could easily happen by mistake.

Thirdly, due to the massive amount of content generated by users every day, it is desirable that the process of detecting (and deleting) Hate Speech is somewhat automated, with the aid of modern available techniques.

The purpose of this article is to introduce the challenges associated with the characterization and detection of this phenomenon, and to present some initial results our research group obtained in collaboration with researchers from Berkman Klein’s Center for Internet and Society.

*Please be aware that this text contains racial slurs and foul language, so viewer discretion is advised.*

---

## But what is, precisely, Hate Speech and how do we find it?

One may believe that Hate Speech is a very easy and natural concept to understand and detect. In fact, some sentences targeting minority or vulnerable groups are very straight forward and, therefore, should be easily considered hateful by pretty much anyone with some common sense. For example, an user in an Online Social Network proclaiming *“I hate Latinos”* or *“Latinas should die”* will be considered hateful by practically any criteria, as in the United States people from Latin America are a minority that have historically suffered discrimination.

However, Hate Speech is not always obvious, which makes the task of automatically detecting and characterizing it very challenging.

Initially, it is necessary to consider that the very conception of Hate Speech is quite loose, and hardly agreed upon. For instance, even some very straight forward “ I hate…” sentences are not considered Hate Speech by many if they are directed at groups of people in positions of power, such as, men or white people: in these cases, some definitions only recognize Hate Speech if the target is a minority or vulnerable group.

Another problem arises from the fact that text in Online Social Networks is noisy, often sarcastic, associated with hyperlinks or images, and often doesn’t contain the entire meaning of a situation. On Twitter, for instance, a Tweet may seem hateful when analyzed in isolation but not when seen in the context of a larger conversation. A good example here is the use of racial slurs: whereas used depreciatively by outgroups, ingroups sometimes use them as terms of camaraderie or community.

These examples capture two aspects in which the detection and characterization of Hate Speech is more complicated than, for instance, the detection of spam or the detection of adult content (which are also desired in most social networks).

The first aspect to be considered is that Hate Speech relies heavily on **context**. This doesn’t mean that context hasn’t been used before in the detection of online misbehavior. It has. For example, the Internet Service Provider associated with an email is a key feature to detect whether it is spam or a legitimate message, and has nothing to do with the message itself. However, with Hate Speech, the context on which a message is sent defines whether it is hateful or not.

The second is that there is no **consensus** in the definition of Hate Speech and, unlike traditional machine learning tasks like object recognition, on which human performance is considered optimal (or a proxy for optimal), people consistently disagree on what may be considered Hate Speech, and algorithms must be trained acknowledging these different interpretations, which may cause high disagreement among human annotators.

Many of these findings stemmed from the Natural Language Processing (NLP) community, which has broadly discussed [how hard it is to separate offensive speech from hate speech](https://arxiv.org/pdf/1703.04009.pdf), [the problems of annotating hate speech](http://anthology.aclweb.org/N/N16/N16-2.pdf#page=98) and the [difficulties of analyzing code words used](https://arxiv.org/pdf/1703.05443.pdf).

Given that the problem of automatically detecting and characterizing hateful content in Online Social Networks has to consider these two aspects, our group shifted the focus of the process from the content itself to the users who spread it, therefore moving from “how to detect Hate Speech?” to “how to detect users that spread Hate Speech?”.

By adopting this approach, we believe it is possible to mitigate the problem of context during the automated detection process. In that sense, an account previously flagged as a possible Hate Speech “spreader” should be worth some attention by the moderation mechanisms. Noticeably this shift alone doesn’t address the problem of consensus, we are currently working on some ideas for that, but for the remainder of this article, let us focus on how we can characterize users, given that identifying hateful users provides us better context.

---

## How do we find hateful users?

Now that we decided that we want to work on a different granularity than most previous work — dealing with users rather than content, we have a problem: how can we find these users? They are certainly not prevalent and we still have the problem of how to define hate speech.
Our approach was the following:

1. We chose Twitter as the platform to conduct our research and Twitter’s own [Hateful Conduct Policy](https://help.twitter.com/rules-and-policies/hateful-conduct-policy) as our source of a Hate Speech definition.

2. Then, we ran an algorithm to randomly collect data from 100,386 accounts, including their last 200 tweets, using Twitter’s API (Application Programming Interface). Notice that as some users have less than 200 tweets, so in total we have 19,536,788 tweets (approximately 194 tweets per person). We also collect the interactions between these accounts, keeping track on how they retweeted each other, as depicted in **Figure 1**.

3. Initially, we identified accounts that used words or expressions that are very unlikely to be used in a context that does not characterize Hate Speech, like holohoax, racial treason and white genocide. Such words and expressions were chosen from two widely recognized databases in the literature ([Hatebase.org](https://www.hatebase.org/) and [ADL’s hate symbol database](https://www.adl.org/education/references/hate-symbols)).

4. Then we collected the users nearby these hate-related lexicon. The nearby part is specially important, as we do not want to limit our sample only to accounts that specifically tweeted the chosen hateful words, as they are more likely to be labeled as Hate Speech spreaders. We needed a diverse sample, because we didn’t want to be restricted to vocabulary that can be obviously characterized as hateful.

5. The final result was a sample of 4,972 users, alongside their 200 tweets. Notice that this actually represents approximately 964 thousand tweets! Which is quite a significant sample.

![]({{ site.baseurl }}/images/2018-01-12-Exploring-User-Centered/users.png)

